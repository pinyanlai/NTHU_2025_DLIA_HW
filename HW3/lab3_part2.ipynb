{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li0bVCTuxc6n"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "#### Lab 3\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 3: Anomaly Detection in Industrial Applications\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlvflhYwCu8Q"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In today's industrial landscape, the ability to detect anomalies in manufacturing processes and products is critical for maintaining quality, efficiency, and safety. This lab focuses on leveraging deep learning techniques for anomaly detection in various industrial applications, using the MVTEC Anomaly Detection Dataset. By employing ImageNet-pretrained models available in torchvision, students will gain hands-on experience in classfying defects and irregularities across different types of industrial products.\n",
    "\n",
    "Throughout this lab, you'll be involved in the following key activities:\n",
    "- Explore and process the MVTec Anomaly Detection Dataset.\n",
    "- Apply ImageNet-pretrained models from [Torchvision](https://pytorch.org/vision/stable/models.html) to detect anomalies in industrial products.\n",
    "- Evaluate the performance of the models to understand their effectiveness in real-world industrial applications.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Understand the principles of anomaly detection in the context of industrial applications.\n",
    "- Learn how to implement and utilize ImageNet-pretrained models for detecting anomalies.\n",
    "- Analyze and interpret the results of the anomaly detection models to assess their practicality in industrial settings.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The MVTec AD Dataset is a comprehensive collection of high-resolution images across different categories of industrial products, such as bottles, cables, and metal nuts, each with various types of defects. This dataset is pivotal for developing and benchmarking anomaly detection algorithms. You can download our lab's dataset [here](https://drive.google.com/file/d/19600hUOpx0hl78TdpdH0oyy-gGTk_F_o/view?usp=share_link). You can drop downloaded data and drop to colab, or you can put into yor google drive.\n",
    "\n",
    "### References\n",
    "- [MVTec AD Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad/data) for the dataset used in this lab.\n",
    "- [Torchvision Models](https://pytorch.org/vision/stable/models.html) for accessing ImageNet-pretrained models to be used in anomaly detection tasks.\n",
    "- [State-of-the-Art Anomaly Detection on MVTec AD](https://paperswithcode.com/sota/anomaly-detection-on-mvtec-ad) for insights into the latest benchmarks and methodologies in anomaly detection applied to the MVTec AD dataset.\n",
    "- [CVPR 2019: MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection] for the original paper of MVTec AD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuiEw1L0Cu8Q"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvLTTCGsCu8R"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# !tar -xvf drive/MyDrive/cable.tar.gz cable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXfjTWKUCu8R"
   },
   "outputs": [],
   "source": [
    "# file_paths = glob.glob('cable/*/*.png')\n",
    "# file_paths = sorted([path for path in file_paths if path.split('/')[-1] in [f'{i:03}.png' for i in range(10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "root_path = r\"D:\\lab3\\dataset\\cable\"\n",
    "subfolders = ['train', 'test', 'ground_truth']\n",
    "\n",
    "# 📊 統計各子資料夾的圖片數量\n",
    "folder_image_counts = {}\n",
    "\n",
    "# 所有圖片集中起來（可選）\n",
    "all_images = []\n",
    "all_paths = []\n",
    "\n",
    "for folder in subfolders:\n",
    "    full_path = os.path.join(root_path, folder)\n",
    "    \n",
    "    # 🔍 遞迴搜尋該資料夾下所有 png / PNG\n",
    "    file_paths = glob.glob(os.path.join(full_path, '**', '*.png'), recursive=True) + \\\n",
    "                 glob.glob(os.path.join(full_path, '**', '*.PNG'), recursive=True)\n",
    "    file_paths = sorted(list(set(file_paths)))  # 去重複\n",
    "\n",
    "    folder_image_counts[folder] = len(file_paths)\n",
    "    all_paths.extend(file_paths)\n",
    "\n",
    "    # 🖼️ 可選：這裡也可以讀圖片（如你原本所做）\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            all_images.append(img)\n",
    "\n",
    "# ✅ 印出統計結果\n",
    "print(\"📊 各資料夾圖片數量：\")\n",
    "for folder, count in folder_image_counts.items():\n",
    "    print(f\" - {folder}: {count} 張圖片\")\n",
    "\n",
    "# ✅ 如果你要全部合併起來用\n",
    "images = np.array(all_images)\n",
    "print(f\"\\n✅ 總共讀入 {len(images)} 張圖片，shape = {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# root_path = r\"D:\\lab3\\dataset\\cable\"\n",
    "\n",
    "# # 🔍 遞迴抓圖，並去重複\n",
    "# file_paths = glob.glob(os.path.join(root_path, '**', '*.png'), recursive=True) + \\\n",
    "#              glob.glob(os.path.join(root_path, '**', '*.PNG'), recursive=True)\n",
    "# file_paths = sorted(list(set(file_paths)))  # ✅ 去除重複\n",
    "\n",
    "# print(f\"📂 共找到 {len(file_paths)} 張圖片（預覽前 10 張）：\")\n",
    "# for path in file_paths[:10]:\n",
    "#     print(\" -\", path)\n",
    "\n",
    "# # 🖼 讀圖\n",
    "# images = []\n",
    "# for path in file_paths:\n",
    "#     img = cv2.imread(path)\n",
    "#     if img is None:\n",
    "#         print(f\"⚠️ 無法讀取圖片：{path}\")\n",
    "#         continue\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     images.append(img)\n",
    "\n",
    "# images = np.array(images)\n",
    "# print(f\"\\n✅ 成功讀入 {len(images)} 張圖片，shape = {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GiOZBRJCu8S"
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for img in tqdm(file_paths):\n",
    "    img = cv2.imread(img)\n",
    "    img = img[..., ::-1]\n",
    "    all_data.append(img)\n",
    "\n",
    "all_data = np.stack(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ii8LH8s4Cu8S"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 取得類別名稱（資料夾名稱）\n",
    "classes = sorted(set([os.path.basename(os.path.dirname(p)) for p in file_paths]))\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# 把每個 class 對應到圖片\n",
    "class_to_imgs = {cls: [] for cls in classes}\n",
    "for img, path in zip(all_data, file_paths):\n",
    "    cls = os.path.basename(os.path.dirname(path))\n",
    "    class_to_imgs[cls].append(img)\n",
    "\n",
    "# 畫圖：每類別選 2 張圖片出來\n",
    "fig, axs = plt.subplots(len(classes), 2, figsize=(6 * 2, 4 * len(classes)))\n",
    "for i, cls in enumerate(classes):\n",
    "    for j in range(2):\n",
    "        axs[i, j].imshow(class_to_imgs[cls][j])\n",
    "        axs[i, j].set_title(f\"{cls} #{j}\")\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-1PsC--M7pT"
   },
   "source": [
    "## A. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGFI8GMpCu8S"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 8\n",
    "images_per_class = 10\n",
    "train_images_per_class = int(images_per_class * 0.8)\n",
    "val_images_per_class = int(images_per_class * 0.2)\n",
    "\n",
    "x_train = []\n",
    "x_val = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    start_index = i * images_per_class\n",
    "    x_train.extend(all_data[start_index:start_index + train_images_per_class])\n",
    "    x_val.extend(all_data[start_index + train_images_per_class:start_index + images_per_class])\n",
    "\n",
    "# The shape changes from (batch_size, height, width, channels) to (batch_size, channels, height, width)\n",
    "x_train = np.transpose(np.array(x_train), (0, 3, 1, 2))\n",
    "x_val = np.transpose(np.array(x_val), (0, 3, 1, 2))\n",
    "\n",
    "y_train = np.concatenate([np.full(train_images_per_class, i) for i in range(num_classes)])\n",
    "y_val = np.concatenate([np.full(val_images_per_class, i) for i in range(num_classes)])\n",
    "\n",
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of x_val: {x_val.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_val: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-CnfsmbCu8T"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.AutoAugment(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        new_x = np.transpose(self.x[idx], (1, 2, 0))\n",
    "        return self.transform(Image.fromarray(new_x)), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53ZVFFacCu8T"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train, train_transforms)\n",
    "val_dataset = MyDataset(x_val, y_val, val_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaLGtT28xc6s"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDX8iDKJCu8U"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# ConvNet as fixed feature extractor (freeze parameters)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_class = 8\n",
    "\n",
    "# change # of class from 1000 into 8 in the last layer\n",
    "model.fc = nn.Linear(num_ftrs, num_class)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvLTU-IfZLqn"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45ol4lpVxc6t"
   },
   "outputs": [],
   "source": [
    "# ✅ HW3 - 四種模型訓練策略\n",
    "\n",
    "# ✅ 共用 imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ 共用資料（請先定義 x_train, y_train, x_val, y_val）\n",
    "# x_train, y_train, x_val, y_val = ...\n",
    "\n",
    "# ✅ 全域變數：儲存訓練結果\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# 共用函數：資料轉 TensorDataset\n",
    "def make_loader(x, y, transform, batch_size=32):\n",
    "    from PIL import Image\n",
    "    processed = []\n",
    "\n",
    "    for img in x:\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.numpy()\n",
    "\n",
    "        # --- ✅ 支援 HWC 與 CHW ---\n",
    "        if img.ndim == 3 and img.shape[-1] == 3:\n",
    "            # 如果是 (H, W, C)：轉成 PIL 交給 transform\n",
    "            img = Image.fromarray(img.astype(np.uint8))\n",
    "            img = transform(img)  # transform 會處理成 tensor 且變成 (C, H, W)\n",
    "\n",
    "        elif img.ndim == 3 and img.shape[0] == 3:\n",
    "            # 如果是 (C, H, W)：直接轉成 tensor（已經是 PyTorch 格式）\n",
    "            img = torch.tensor(img).float() / 255.\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"圖片 shape 有誤：{img.shape}\")\n",
    "\n",
    "        processed.append(img)\n",
    "\n",
    "    x_tensor = torch.stack(processed)\n",
    "    y_tensor = torch.from_numpy(y).long()\n",
    "\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "# 共用函數：訓練\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, epochs=50, mode=\"model\"):\n",
    "    global train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "    model = model.cuda()\n",
    "    best_acc = -1\n",
    "    train_losses.clear()\n",
    "    val_losses.clear()\n",
    "    train_accuracies.clear()\n",
    "    val_accuracies.clear()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_accuracies.append(100. * correct / len(train_loader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_acc = 100. * correct / len(val_loader.dataset)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"{mode}_best.pth\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"[{epoch+1}/{epochs}] Train Acc: {train_accuracies[-1]:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n",
    "\n",
    "# 其餘內容保持不變（略）\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 🔹 1. Baseline CNN\n",
    "# ==========================================================\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_loader = make_loader(x_train, y_train, transform)\n",
    "val_loader = make_loader(x_val, y_val, transform)\n",
    "\n",
    "model = SimpleCNN(num_classes=8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_acc, val_acc, train_loss, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, mode=\"baseline\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# 🔹 2. Data Augmentation\n",
    "# ==========================================================\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter()\n",
    "])\n",
    "train_loader = make_loader(x_train, y_train, aug_transform)\n",
    "val_loader = make_loader(x_val, y_val, transform)\n",
    "\n",
    "model = SimpleCNN(num_classes=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_acc, val_acc, train_loss, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, mode=\"augmented\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"augmented_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# 🔹 3. Pretrained ResNet18\n",
    "# ==========================================================\n",
    "model = models.resnet18(weights=\"DEFAULT\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(model.fc.in_features, 8)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "train_loader = make_loader(x_train, y_train, transform)\n",
    "val_loader = make_loader(x_val, y_val, transform)\n",
    "train_acc, val_acc, train_loss, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, mode=\"resnet18\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"resnet18_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# 🔹 4. ResNet18 + Learning Rate Scheduler\n",
    "# ==========================================================\n",
    "model = models.resnet18(weights=\"DEFAULT\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(model.fc.in_features, 8)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader)*30, eta_min=0)\n",
    "train_acc, val_acc, train_loss, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=scheduler, mode=\"resnet18_sched\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"resnet18_sched_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjmYxAJnxc6t"
   },
   "source": [
    "### Visualizing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHpS0Q7vxc6t"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# # Plotting training and validation accuracy\n",
    "# ax[0].plot(train_accuracies)\n",
    "# ax[0].plot(val_accuracies)\n",
    "# ax[0].set_title('Model Accuracy')\n",
    "# ax[0].set_xlabel('Epochs')\n",
    "# ax[0].set_ylabel('Accuracy')\n",
    "# ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# # Plotting training and validation loss\n",
    "# ax[1].plot(train_losses)\n",
    "# ax[1].plot(val_losses)\n",
    "# ax[1].set_title('Model Loss')\n",
    "# ax[1].set_xlabel('Epochs')\n",
    "# ax[1].set_ylabel('Loss')\n",
    "# ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVDWBwv6Cu8V"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEztHBDjCu8V"
   },
   "source": [
    "### Load Trained Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# ✅ 評估函數（固定架構與資料）\n",
    "def evaluate_model(model, model_path, val_loader, device=\"cuda\"):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device) / 255.\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    acc = 100. * test_correct / test_total\n",
    "    print(f\"✅ {model_path} Test accuracy: {acc:.2f}%\\n\")\n",
    "    return acc\n",
    "\n",
    "# ✅ 模型初始化對應\n",
    "\n",
    "def get_model(model_type):\n",
    "    if model_type == \"resnet\":\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 8)\n",
    "    elif model_type == \"simple\":\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self, num_classes=8):\n",
    "                super().__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "                )\n",
    "                self.classifier = nn.Linear(64, num_classes)\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = x.view(x.size(0), -1)\n",
    "                return self.classifier(x)\n",
    "        model = SimpleCNN()\n",
    "    else:\n",
    "        raise ValueError(f\"❌ 不支援的模型類型：{model_type}\")\n",
    "    return model\n",
    "\n",
    "# ✅ 四種方案對應路徑與類型（正確抓取）\n",
    "model_configs = {\n",
    "    \"Baseline\": (\"baseline_best.pth\", \"simple\"),\n",
    "    \"Augmented\": (\"augmented_best.pth\", \"simple\"),\n",
    "    \"ResNet18\": (\"resnet18_best.pth\", \"resnet\"),\n",
    "    \"ResNet18 + Scheduler\": (\"resnet18_sched_best.pth\", \"resnet\")\n",
    "}\n",
    "\n",
    "# ✅ 執行四種模型的測試（需定義 val_loader）\n",
    "for name, (path, model_type) in model_configs.items():\n",
    "    print(f\"\\n=== Evaluating: {name} ===\")\n",
    "    model = get_model(model_type)\n",
    "    evaluate_model(model, path, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 評估函數\n",
    "# def evaluate_model(model, model_path, val_loader, device=\"cuda\"):\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "#     model = model.to(device)\n",
    "#     model.eval()\n",
    "\n",
    "#     test_correct = 0\n",
    "#     test_total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "#             images = images.to(device) / 255.\n",
    "#             labels = labels.to(device).long()\n",
    "\n",
    "#             outputs = model(images)\n",
    "#             predicted = outputs.argmax(dim=1)\n",
    "\n",
    "#             test_correct += (predicted == labels).sum().item()\n",
    "#             test_total += labels.size(0)\n",
    "\n",
    "#     acc = 100. * test_correct / test_total\n",
    "#     print(f\"✅ {model_path} Test accuracy: {acc:.2f}%\\n\")\n",
    "#     return acc\n",
    "\n",
    "# # 匯入模型定義\n",
    "# from torchvision import models\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # 四種模型對應的檔案名稱與模型初始化邏輯\n",
    "# model_paths = {\n",
    "#     \"Baseline\": \"baseline_best.pth\",\n",
    "#     \"Augmented\": \"augmented_best.pth\",\n",
    "#     \"ResNet18\": \"resnet18_best.pth\",\n",
    "#     \"ResNet18 + Scheduler\": \"resnet18_sched_best.pth\"\n",
    "# }\n",
    "\n",
    "# def get_model(name):\n",
    "#     if \"resnet18\" in name.lower():\n",
    "#         model = models.resnet18(weights=None)\n",
    "#         model.fc = nn.Linear(model.fc.in_features, 8)\n",
    "#     else:\n",
    "#         # 使用與訓練時相同的自定義 CNN 結構\n",
    "#         class SimpleCNN(nn.Module):\n",
    "#             def __init__(self, num_classes=8):\n",
    "#                 super().__init__()\n",
    "#                 self.features = nn.Sequential(\n",
    "#                     nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "#                     nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "#                     nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
    "#                 )\n",
    "#                 self.classifier = nn.Linear(64, num_classes)\n",
    "#             def forward(self, x):\n",
    "#                 x = self.features(x)\n",
    "#                 x = x.view(x.size(0), -1)\n",
    "#                 return self.classifier(x)\n",
    "#         model = SimpleCNN()\n",
    "#     return model\n",
    "\n",
    "# # 執行四種模型的測試\n",
    "# for name, path in model_paths.items():\n",
    "#     print(f\"\\n=== Evaluating: {name} ===\")\n",
    "#     model = get_model(name)\n",
    "#     evaluate_model(model, path, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DA1qHXpCu8V"
   },
   "outputs": [],
   "source": [
    "# # Load the trained weights\n",
    "# model.load_state_dict(torch.load('model_classification.pth'))\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in val_loader:\n",
    "\n",
    "#         images = images.cuda()\n",
    "#         images = (images) / 255.\n",
    "\n",
    "#         labels = labels.cuda()\n",
    "#         labels = labels.long()\n",
    "\n",
    "#         outputs = model(images)\n",
    "\n",
    "#         predicted = outputs.argmax(-1)\n",
    "#         print(predicted)\n",
    "#         print(labels)\n",
    "#         test_correct += (predicted == labels).sum().item()\n",
    "#         test_total += labels.size(0)\n",
    "\n",
    "# print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jG6DuAgcEgxj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
